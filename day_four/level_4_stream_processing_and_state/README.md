

# ðŸš° Text Processor â€“ Level 4: Stream-Based Processing & Stateful Pipelines

> Author: **ANURAG**

A powerful and extensible text transformation pipeline that processes text as a stream of lines. This level introduces stream-aware processors, enabling dynamic fan-in, fan-out, and stateful behaviors like counting or buffering â€” all driven by the same dynamic `pipeline.yaml`.



## ðŸ“ Project Structure

```
level_4_stream_processing_and_state/
â”œâ”€â”€ main.py                  # Entry point
â”œâ”€â”€ cli.py                   # Typer-based CLI interface
â”œâ”€â”€ core.py                  # Core streaming pipeline engine
â”œâ”€â”€ pipeline.py              # Dynamic pipeline loader from YAML
â”œâ”€â”€ types.py                 # StreamProcessorFn type definitions
â”œâ”€â”€ pipeline.yaml            # YAML config defining processing steps
â””â”€â”€ processors/
    â”œâ”€â”€ upper.py             # Reuses str -> str to_uppercase
    â”œâ”€â”€ snake.py             # Reuses str -> str to_snakecase
    â”œâ”€â”€ fanout_splitter.py   # Stream-based fan-out processor (split by space)
    â””â”€â”€ stateful_counter.py  # Stream-based stateful processor (line counter)
```


## âš™ï¸ Features

âœ… Dynamic processor configuration via `pipeline.yaml`
âœ… Stream-based processor interface: `Iterator[str] -> Iterator[str]`
âœ… Backward compatibility with `str -> str` processors
âœ… Support for fan-out (split lines), fan-in (combine lines), and stateful logic
âœ… Cleanly wrapped function decorators for legacy processor reuse
âœ… Easy extension via class-based processors with configuration



## ðŸ“Œ Installation

```
pip install typer[all] pyyaml
```

---

## ðŸ§ª Example Usage

```
python main.py --input input.txt --config pipeline.yaml
```

Or with output:

```
python main.py --input input.txt --config pipeline.yaml --output result.txt
```

---

## ðŸ§± YAML Pipeline Example

```
pipeline:
  - type: processors.stateful_counter.LineCounter
  - type: processors.upper.to_uppercase
  - type: processors.fanout_splitter.SplitLines
```

This pipeline:

1. Adds line numbers (stateful)
2. Converts to uppercase
3. Splits each line by spaces (fan-out)


## ðŸ” Stream Processor Signature

```
# types.py
StreamProcessorFn = Callable[[Iterator[str]], Iterator[str]]
```

All processors now operate on streams of lines, enabling more powerful transformations.

To reuse old `str -> str` processors:

```
def str_to_stream(fn: Callable[[str], str]) -> StreamProcessorFn:
    def wrapped(lines: Iterator[str]) -> Iterator[str]:
        for line in lines:
            yield fn(line)
    return wrapped
```


## ðŸ“‚ Sample Processors

### âœ… Legacy str -> str (wrapped for streaming)

**processors/upper.py**

```
def to_uppercase(line: str) -> str:
    return line.strip().upper()
```

### ðŸ”„ Fan-out Processor

**processors/fanout\_splitter.py**

```
class SplitLines:
    def __init__(self, delimiter=" "):
        self.delimiter = delimiter

    def __call__(self, lines: Iterator[str]) -> Iterator[str]:
        for line in lines:
            yield from line.strip().split(self.delimiter)
```

### ðŸ”¢ Stateful Processor

**processors/stateful\_counter.py**

```
class LineCounter:
    def __init__(self):
        self.count = 0

    def __call__(self, lines: Iterator[str]) -> Iterator[str]:
        for line in lines:
            self.count += 1
            yield f"LINE {self.count}:\n{line.strip()}"
```



## ðŸ“¥ Input / Output Examples

| Input (`input.txt`)      | Pipeline Steps                      | Output Lines                                         |
| ------------------------ | ----------------------------------- | ---------------------------------------------------- |
| `Hello World`            | LineCounter â†’ to\_uppercase â†’ Split | `LINE 1:`<br>`HELLO`<br>`WORLD`                      |
| `Python is Surely gREAt` | LineCounter â†’ to\_uppercase â†’ Split | `LINE 2:`<br>`PYTHON`<br>`IS`<br>`SURELY`<br>`GREAT` |
| `PiplInes Are GoOd`      | LineCounter â†’ to\_uppercase â†’ Split | `LINE 3:`<br>`PIPLINES`<br>`ARE`<br>`GOOD`           |



## ðŸ§¯ Error Handling

If a processor path is invalid or cannot be loaded:

```
ImportError: Could not load processor processors.fake.module: No module named 'processors.fake'
```

The system will give a clear traceback to guide you.

---

## ðŸ§  Advanced Behavior Supported

* âœ… Emit 0, 1, or many lines from 1 input (fan-out/fan-in)
* âœ… Maintain internal state across lines (e.g., line counter)
* âœ… Configure processors at initialization (via class params)
* âœ… Seamless fallback to function-based legacy processors

---

## ðŸ§© Extending with New Processors

1. Create a new file under `processors/`
2. Define a class with `__init__` and `__call__(self, lines: Iterator[str])`
3. Add to your `pipeline.yaml` using its full import path:

```
pipeline:
  - type: processors.my_processor.MyClass
```

---

## âœ… Checklist

* [x] Supports streaming processors (`Iterator[str] -> Iterator[str]`)
* [x] Reuses existing `str -> str` processors
* [x] Introduces fan-out and stateful processing
* [x] Clean class-based design with configuration support
* [x] Pipeline.yaml remains unchanged from Level 3


## ðŸ“œ License

MIT License
